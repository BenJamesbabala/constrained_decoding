{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a sketch of the constrained decoding algorithm by Hokamp & Liu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sortedcontainers import SortedListWithKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imagine a max_source_len x constraint_len+1 grid\n",
    "# at the top left corner, there is a triangle with constraint_len-1 sides cut out\n",
    "# at the bottom right corner, there is a triangle with constraint_len sides cut out\n",
    "\n",
    "# we move to the right, filling the beams in each column starting with the bottommost, and moving upwards\n",
    "#        - filling the beams in a column can be done in parallel, since there are no dependencies within the column\n",
    "\n",
    "# the horizontal (t) axis represents time\n",
    "#     - every hypothesis in a column t has the same number of tokens\n",
    "# the vertical axis (j) represents coverage of constraints\n",
    "#     - every hypothesis in a row j covers the same number of constraint tokens\n",
    "\n",
    "# FILLING CELL (i,j)\n",
    "# there are two source beams from which we can generate hypotheses:\n",
    "# LEFT (cell (i-1, j))\n",
    "#    - this cell can only generate \n",
    "# BELOW+LEFT (cell (i-1, j-1))\n",
    "#    - this cell can add constraints in two ways:\n",
    "#      (1) constraints which are unfinished _MUST_ be continued\n",
    "#      (2) new constraints can be started\n",
    "#    - hypotheses from this beam always update the constraint coverage\n",
    "\n",
    "# Generating constraint hypotheses\n",
    "# the hypothesis object holds all of the states needed to generate the n-best continuations at the next timestep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTES:\n",
    "# without a special feature, generating a word and using the same word from a constraint have the same score,\n",
    "# thus we need a way to decide whether we are generating a word, or starting a new constraint which begins with \n",
    "# that word\n",
    "# - the constraint pointer model is one way of scoring hypotheses from the different sources differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "sample_constraints = [\n",
    "    [1,2],\n",
    "    [5,6,7]\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConstraintHypothesis:\n",
    "    \"\"\"A (partial) hypothesis which maintains an additional constraint coverage object\n",
    "    \n",
    "    Args:\n",
    "        token (unicode): the surface form of this hypothesis\n",
    "        score (float): the score of this hypothesis (higher is better)\n",
    "        constraints (list of lists): the constraints for this search instance, may be empty\n",
    "            each list represents a separate constraint\n",
    "        payload (:obj:): additional data that comes with this hypothesis. Client functions may \n",
    "            require certain data to be present in the payload\n",
    "        backpointer (:obj:`ConstraintHypothesis`): a pointer to the hypothesis object which generated this one\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, token, score, constraints, payload=None, backpointer=None):\n",
    "        self.token = token\n",
    "        self.score = score\n",
    "        self.backpointer = backpointer\n",
    "        self.payload = payload\n",
    "        self.coverage = self.init_coverage(constraints)\n",
    "    \n",
    "    def init_coverage(self, constraints):\n",
    "        coverage = []\n",
    "        for c in constraints:\n",
    "            coverage.append(np.zeros(len(c), dtype='int16'))\n",
    "        return coverage\n",
    "    \n",
    "\n",
    "            \n",
    "class AbstractBeam():\n",
    "    \n",
    "    def __init__(self, size):\n",
    "        # note: here we assume bigger scores are better\n",
    "        self.hypotheses = SortedListWithKey(key=lambda x: -x['score'])\n",
    "        self.size = size\n",
    "    \n",
    "    def add(self, hyp):\n",
    "        self.hypotheses.add(hyp)\n",
    "        if len(self.hypotheses) > self.size:\n",
    "            assert len(self.hypotheses) == self.size + 1\n",
    "            del self.hypotheses[-1]\n",
    "        \n",
    "\n",
    "def get_generation_hyps(beam, hyp_generation_func):\n",
    "    \"\"\"return all hyps which are continuations of the hyps on this beam\n",
    "    \n",
    "    hyp_generation_func maps `(hyp) --> continuations`\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "        \n",
    "def get_new_constraint_hyps(beam, constraints, constraint_hyp_func):\n",
    "    \"\"\"return all hyps which start a new constraint from the hyps on this beam\n",
    "    \n",
    "    constraint_hyp_func maps `(hyp, constraints) --> continuations`\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_continued_constraint_hyps(beam, constraints, constraint_hyp_func):\n",
    "    \"\"\"return all hyps which continue the unfinished constraints on this beam\n",
    "    \n",
    "    constraint_hyp_func maps `(hyp, constraints) --> forced_continuations`\n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Beam():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a beam implements two functions:\n",
    "    -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
