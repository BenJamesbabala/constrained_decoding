{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX TITAN X (0000:03:00.0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "from constrained_decoding import create_constrained_decoder\n",
    "from constrained_decoding.translation_model.nematus_tm import NematusTranslationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_config(filename):\n",
    "    # defaults -- params which are inputs to `nematus/translate.py`, but aren't part of the persisted *.json config\n",
    "    translate_config = {\n",
    "        \"return_alignment\": False\n",
    "    }\n",
    "    config = json.loads(codecs.open(filename, encoding='utf8').read())\n",
    "    return dict(translate_config, **config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Working: test with hard-coded config and model paths\n",
    "\n",
    "configs = [\n",
    "    '/media/1tb_drive/nematus_ape_experiments/amunmt_ape_pretrained/system/models/src-pe/model.npz.json'\n",
    "]\n",
    "\n",
    "models = [\n",
    "    '/media/1tb_drive/nematus_ape_experiments/amunmt_ape_pretrained/system/models/src-pe/model.4-best.averaged.npz'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building f_init... Done\n",
      "Building f_next.. Done\n"
     ]
    }
   ],
   "source": [
    "# remember Nematus needs _encoded_ utf8\n",
    "configs = [load_config(f) for f in configs]\n",
    "\n",
    "# build ensembled TM\n",
    "nematus_tm = NematusTranslationModel(models, configs, model_weights=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nematus_tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from constrained_decoding.server import run_imt_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decoder = create_constrained_decoder(nematus_tm)\n",
    "#     app.decoders = {k: create_constrained_decoder(v) for k, v in models.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model_dict = {('en', 'de'): nematus_tm}\n",
    "\n",
    "# run_imt_server(models=model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[1526],\n",
      "        [ 732],\n",
      "        [   3],\n",
      "        [   0]]])]\n",
      "[[[1526]\n",
      "  [ 732]\n",
      "  [   3]\n",
      "  [   0]]]\n"
     ]
    }
   ],
   "source": [
    "#     model = app.models[(source_lang, target_lang)]\n",
    "    # TODO: create constrained decoders from all models\n",
    "#     decoder = app.decoders[(source_lang, target_lang)]\n",
    "    # WORKING: call the correct model\n",
    "    # WORKING: remember we support multiple inputs for each model (i.e. each model may be an ensemble where sub-models\n",
    "    # accept different inputs)\n",
    "\n",
    "    # Note: for now we only support one source input\n",
    "\n",
    "length_factor = 1.5\n",
    "beam_size = 5\n",
    "n_best = 5\n",
    "\n",
    "    \n",
    "source_sentence = u'Help me .'\n",
    "inputs = [source_sentence]\n",
    "\n",
    "mapped_inputs = model.map_inputs(inputs)\n",
    "print(mapped_inputs)\n",
    "\n",
    "input_constraints = []\n",
    "# if constraints is not None:\n",
    "#     input_constraints = model.map_constraints(constraints)\n",
    "\n",
    "# import ipdb; ipdb.set_trace()\n",
    "start_hyp = model.start_hypothesis(mapped_inputs, input_constraints)\n",
    "\n",
    "search_grid = decoder.search(start_hyp=start_hyp, constraints=input_constraints,\n",
    "                             max_hyp_len=int(round(len(mapped_inputs[0][0]) * length_factor)),\n",
    "                             beam_size=beam_size)\n",
    "\n",
    "best_output, best_alignments = decoder.best_n(search_grid, model.eos_token, n_best=n_best,\n",
    "                                              return_model_scores=False, return_alignments=True,\n",
    "                                              length_normalization=True)\n",
    "\n",
    "if n_best > 1:\n",
    "    # start from idx 1 to cut off `None` at the beginning of the sequence\n",
    "    # separate each n-best list with newline\n",
    "    decoder_output = u'\\n'.join([u' '.join(s[0][1:]) for s in best_output]) + u'\\n\\n'\n",
    "else:\n",
    "    # start from idx 1 to cut off `None` at the beginning of the sequence\n",
    "    decoder_output = u' '.join(best_output[0][1:])\n",
    "\n",
    "# Note alignments are always an n-best list (may be n=1)\n",
    "# if write_alignments is not None:\n",
    "#     with codecs.open(write_alignments, 'a+', encoding='utf8') as align_out:\n",
    "#         align_out.write(json.dumps([a.tolist() for a in best_alignments]) + u'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Help me .\\nHilfe me .\\nHilfe .\\nHilfe bei mir .\\nHilfe mir .\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
